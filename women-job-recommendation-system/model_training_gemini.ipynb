{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3e3210",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'google.generativeai' has no attribute 'compare_texts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Apply similarity score for each job description\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: palm_similarity(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskills_required\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_title\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Train model (example setup, adjust as needed)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Apply similarity score for each job description\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: palm_similarity(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskills_required\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_title\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Train model (example setup, adjust as needed)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36mpalm_similarity\u001b[1;34m(skills, job_desc)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpalm_similarity\u001b[39m(skills, job_desc):\n\u001b[1;32m---> 15\u001b[0m     response \u001b[38;5;241m=\u001b[39m palm\u001b[38;5;241m.\u001b[39mcompare_texts(skills, job_desc)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'google.generativeai' has no attribute 'compare_texts'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "import google.generativeai as palm\n",
    "\n",
    "# Initialize Google PaLM Client\n",
    "palm.configure(api_key='AIzaSyDKOjp4ccw4rdJ2u7qaG-rsbWr7wRzslyE')\n",
    "\n",
    "# Load job dataset\n",
    "df = pd.read_csv('job_skills.csv')\n",
    "\n",
    "# Define a function to get similarity score\n",
    "def palm_similarity(skills, job_desc):\n",
    "    response = palm.compare_texts(skills, job_desc)\n",
    "    return response['score']\n",
    "\n",
    "# Apply similarity score for each job description\n",
    "df['similarity_score'] = df.apply(lambda row: palm_similarity(row['skills_required'], row['job_title']), axis=1)\n",
    "\n",
    "# Train model (example setup, adjust as needed)\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['skills_required'] + ' ' + df['job_title'])\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(vectorizer, 'job_recommendation_model_gemini.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b2218",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIzaSyDKOjp4ccw4rdJ2u7qaG-rsbWr7wRzslyE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16b6095",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'google.generativeai' has no attribute 'generate_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m similarity[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate similarity score for each job listing in the dataset\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: compute_similarity(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskills_required\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_title\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Proceed with model training using TF-IDF as an additional feature if needed\u001b[39;00m\n\u001b[0;32m     33\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m similarity[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate similarity score for each job listing in the dataset\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: compute_similarity(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskills_required\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_title\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Proceed with model training using TF-IDF as an additional feature if needed\u001b[39;00m\n\u001b[0;32m     33\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m, in \u001b[0;36mcompute_similarity\u001b[1;34m(skills, job_desc)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_similarity\u001b[39m(skills, job_desc):\n\u001b[1;32m---> 24\u001b[0m     skills_embedding \u001b[38;5;241m=\u001b[39m get_text_embedding(skills)\n\u001b[0;32m     25\u001b[0m     job_desc_embedding \u001b[38;5;241m=\u001b[39m get_text_embedding(job_desc)\n\u001b[0;32m     26\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m cosine_similarity([skills_embedding], [job_desc_embedding])\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mget_text_embedding\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_text_embedding\u001b[39m(text):\n\u001b[1;32m---> 16\u001b[0m     response \u001b[38;5;241m=\u001b[39m palm\u001b[38;5;241m.\u001b[39mgenerate_embeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtextembedding-gecko\u001b[39m\u001b[38;5;124m'\u001b[39m, input_text\u001b[38;5;241m=\u001b[39mtext)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'google.generativeai' has no attribute 'generate_embeddings'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import joblib\n",
    "import google.generativeai as palm\n",
    "\n",
    "# Initialize Google PaLM Client\n",
    "palm.configure(api_key='AIzaSyDKOjp4ccw4rdJ2u7qaG-rsbWr7wRzslyE')\n",
    "\n",
    "# Load job dataset\n",
    "df = pd.read_csv('job_skills.csv')\n",
    "\n",
    "# Function to get text embedding using PaLM\n",
    "def get_text_embedding(text):\n",
    "    response = palm.generate_embeddings(model='textembedding-gecko', input_text=text)\n",
    "    if 'embedding' in response:\n",
    "        return np.array(response['embedding'])\n",
    "    else:\n",
    "        raise ValueError(\"Failed to generate embedding. Check API usage limits or API key.\")\n",
    "\n",
    "# Function to compute similarity score between skills and job description\n",
    "def compute_similarity(skills, job_desc):\n",
    "    skills_embedding = get_text_embedding(skills)\n",
    "    job_desc_embedding = get_text_embedding(job_desc)\n",
    "    similarity = cosine_similarity([skills_embedding], [job_desc_embedding])\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Calculate similarity score for each job listing in the dataset\n",
    "df['similarity_score'] = df.apply(lambda row: compute_similarity(row['skills_required'], row['job_title']), axis=1)\n",
    "\n",
    "# Proceed with model training using TF-IDF as an additional feature if needed\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['skills_required'] + ' ' + df['job_title'])\n",
    "\n",
    "# Save the vectorizer model\n",
    "joblib.dump(vectorizer, 'job_recommendation_model_gemini.pkl')\n",
    "\n",
    "# Optionally, save the dataframe with similarity scores for further analysis\n",
    "df.to_csv('job_skills_with_similarity.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da304ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matching jobs for given skills:\n",
      "           job_title  similarity_score\n",
      "1     Data Scientist          0.831126\n",
      "0  Software Engineer          0.430064\n",
      "2        UX Designer          0.000000\n",
      "3    Product Manager          0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "\n",
    "# Load job dataset\n",
    "df = pd.read_csv('job_skills.csv')\n",
    "\n",
    "# Combine skills and job descriptions for vectorization\n",
    "df['combined_text'] = df['skills_required'] + ' ' + df['job_title']\n",
    "\n",
    "# Vectorize the combined text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['combined_text'])\n",
    "\n",
    "# Define a function to calculate similarity between user skills and job descriptions\n",
    "def compute_similarity(user_skills):\n",
    "    # Vectorize user skills\n",
    "    user_skills_vector = vectorizer.transform([user_skills])\n",
    "    # Compute cosine similarity between user skills and each job listing\n",
    "    similarity_scores = cosine_similarity(user_skills_vector, tfidf_matrix).flatten()\n",
    "    return similarity_scores\n",
    "\n",
    "# Example usage to find top matches for given user skills\n",
    "user_skills = \"Python, Machine Learning, Data Analysis\"\n",
    "df['similarity_score'] = compute_similarity(user_skills)\n",
    "\n",
    "# Get top 5 matching jobs\n",
    "top_matches = df.nlargest(5, 'similarity_score')[['job_title', 'similarity_score']]\n",
    "\n",
    "# Save the vectorizer model and data\n",
    "joblib.dump(vectorizer, 'job_recommendation_model_tfidf.pkl')\n",
    "df.to_csv('job_skills_with_similarity.csv', index=False)\n",
    "\n",
    "print(\"Top matching jobs for given skills:\")\n",
    "print(top_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec5baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
